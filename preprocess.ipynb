{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import joblib\n",
    "\n",
    "# get_data by specifying folder_name and file_name\n",
    "def get_data(folder_name, file_name):\n",
    "    \"\"\"\n",
    "        loads the 'file_name' csv file from the 'folder_name' folder\n",
    "        get_data(folder_name, file_name) : Str Str -> Pandas DataFrame \n",
    "    \"\"\"\n",
    "    source_path = os.path.join('..\\data', folder_name)\n",
    "    if file_name == 'sample_submission.csv':\n",
    "        path_data = os.path.join(source_path, file_name)\n",
    "        data_df = pd.read_csv(path_data)\n",
    "    elif file_name == 'train.csv':\n",
    "        path_data = os.path.join(source_path, file_name)\n",
    "        data_df = pd.read_csv(path_data)\n",
    "    elif file_name == 'games.csv':\n",
    "        path_data = os.path.join(source_path, file_name)\n",
    "        data_df = pd.read_csv(path_data, parse_dates = ['created_at'])\n",
    "    elif file_name == 'turns.csv':\n",
    "        path_data = os.path.join(source_path, file_name)\n",
    "        data_df = pd.read_csv(path_data)\n",
    "    else:\n",
    "        path_data = os.path.join(source_path, file_name)\n",
    "        data_df = pd.read_csv(path_data)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "# Custom Transformer to add bot features\n",
    "\n",
    "class AddBotFeatures (BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform (self, X):\n",
    "        bot_names = ['BetterBot', 'STEEBot', 'HastyBot']\n",
    "        bot_data = X.loc[X['nickname'].isin(bot_names)].copy()\n",
    "        bot_data.rename(columns={'nickname':'bot_nickname', 'score': 'bot_score', 'rating': 'bot_rating'}, inplace= True )\n",
    "        human_data = X.loc[~X['nickname'].isin(bot_names)].copy()\n",
    "        \n",
    "        # Join the two dataframe\n",
    "        new_df = human_data.join(bot_data.set_index('game_id'), on='game_id')\n",
    "\n",
    "        # Move the rating column to the end\n",
    "        column_to_move = new_df.pop(\"rating\")\n",
    "\n",
    "        new_df.insert(6, \"rating\", column_to_move)\n",
    "\n",
    "        return new_df\n",
    "\n",
    "\n",
    "def split_data(df):\n",
    "    \"\"\"Splits df into training, testing and validation sets\n",
    "        split_data: Pandas DataFrame -> Pandas DataFrame, Pandas DataFrame, Pandas DataFrame, Pandas DataFrame\n",
    "    \"\"\"\n",
    "    X_data = df.drop(columns = \"rating\")\n",
    "    train_y = df[\"rating\"].copy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, train_y, test_size=0.3, random_state=123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# PREPROCESSING PIPELINE\n",
    "\n",
    "# Standardize the score, bot_score and bot_rating\n",
    "Preprocess = ColumnTransformer([\n",
    "    ('StandardScaler', StandardScaler(), [2,4,5]),\n",
    "    ('oneHotEncoding', OneHotEncoder(), [3])\n",
    "])\n",
    "\n",
    "\n",
    "def evaluate_model(test_data,true_labels, model):\n",
    "    \"\"\"\n",
    "        evaluate model and return the RMSE of the model\n",
    "    \"\"\"\n",
    "    # test_X = Preprocess.transform(test_data)\n",
    "    predictions = model.predict(test_data)\n",
    "    error = abs(predictions - true_labels)\n",
    "    rmse = np.sqrt(np.mean(error))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def save_model_or_pipeline(model, model_name, folder):\n",
    "    \"\"\"\n",
    "        save_model saves the model in the model folder\n",
    "        save_model(model,model_name): ML model Str -> None\n",
    "    \"\"\"\n",
    "    model_n = model_name + '.pkl'\n",
    "    model_path = os.path.join('..', folder, model_n)\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "\n",
    "def load_model_or_pipeline(model_name, folder_name):\n",
    "    \"\"\"\n",
    "        load_model loads the model named 'model_name'\n",
    "    \"\"\"\n",
    "    model_n = model_name + '.pkl'\n",
    "    model_path = os.path.join('..',  folder_name, model_n)\n",
    "    load_rf = joblib.load(model_path)\n",
    "    return load_rf\n",
    "\n",
    "\n",
    "\n",
    "def save_submission(submission_name, model, test_data):\n",
    "    \"\"\"\n",
    "        save_submission requires 3 inputs: submission_name which is the name of the submission file,\n",
    "        model which is the name of the model to be loaded from the models folder to make the predictions and\n",
    "        pipeline_name which is the name of the preprocessing pipeline to be load from the pipeline folder\n",
    "        save_submission: Str Str Str -> Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    sample_submission = get_data('main_data', 'sample_submission.csv')\n",
    "    \n",
    "    # test_data = get_data('main_data', 'test.csv')\n",
    "\n",
    "    # AddBot = load_model_or_pipeline('Add_bot_features', 'pipeline')\n",
    "    # testing_data = AddBot.transform(test_data)\n",
    "    # testing_data.drop(columns = 'rating', inplace = True)\n",
    "    \n",
    "    # Data Pipeline\n",
    "    # Preprocess = load_model_or_pipeline(pipeline_name, 'pipeline')\n",
    "    \n",
    "    # scaled_testing = Preprocess.transform(testing_data)\n",
    "\n",
    "    rating = model.predict(test_data)\n",
    "    sample_submission['rating'] = rating\n",
    "\n",
    "    file_name = submission_name + '.csv'\n",
    "    prediction_path = os.path.join('../predictions', file_name)\n",
    "    sample_submission.to_csv(prediction_path, index = False)\n",
    "\n",
    "    return sample_submission\n",
    "\n",
    "\n",
    "## Data Preprocess\n",
    "\n",
    "def get_full_test_set(df):\n",
    "\n",
    "    games_data = get_data('main_data', 'games.csv')\n",
    "\n",
    "    full_train = df.join(games_data.set_index('game_id'), on='game_id')\n",
    "\n",
    "    full_train['game_created_time'] = games_data.created_at.dt.time\n",
    "    #full_train['game_created_date'] = games_data.created_at.dt.date\n",
    "    full_train['game_created_day'] = games_data.created_at.dt.day_of_week\n",
    "    full_train['game_created_time'] = full_train['game_created_time'].apply(lambda x: (x.hour + x.minute/60 + x.second/3600))\n",
    "\n",
    "    bot_names = ['BetterBot', 'STEEBot', 'HastyBot']\n",
    "\n",
    "    full_train.drop(columns = 'created_at', inplace = True)\n",
    "\n",
    "    full_train['first'] = np.where(full_train['first'].isin(bot_names), 1, 0)\n",
    "\n",
    "    full_train[\"lexicon\"] = full_train[\"lexicon\"].apply(lambda x: \"NWL20\" if x == \"NSWL20\" else x)\n",
    "\n",
    "    turns_data = get_data('main_data', 'turns.csv')\n",
    "\n",
    "    temp = turns_data.groupby(['game_id','nickname'])['points'].agg([np.mean, np.median, np.std]).reset_index()\n",
    "    total_turns = turns_data.groupby(['game_id'])['turn_number'].max()\n",
    "\n",
    "    turn_type = turns_data.groupby(['game_id','nickname'])['turn_type'].unique().reset_index()\n",
    "\n",
    "    bot_data = turn_type.loc[turn_type['nickname'].isin(bot_names)].copy()\n",
    "    bot_data.rename(columns={'nickname':'bot_nickname', 'turn_type': 'bot_turn_type'}, inplace= True )\n",
    "\n",
    "    human_data = turn_type.loc[~turn_type['nickname'].isin(bot_names)].copy()\n",
    "\n",
    "    # Join the two dataframe\n",
    "    new_df = human_data.join(bot_data.set_index('game_id'), on='game_id')\n",
    "\n",
    "    bot_data = temp.loc[temp['nickname'].isin(bot_names)].copy()\n",
    "    bot_data.rename(columns={'nickname':'bot_nickname', 'mean': 'bot_mean', 'median': 'bot_median', 'std': 'bot_std'}, inplace= True )\n",
    "\n",
    "    human_data = temp.loc[~temp['nickname'].isin(bot_names)].copy()\n",
    "\n",
    "    # Join the two dataframe\n",
    "    temp_df = human_data.join(bot_data.set_index('game_id'), on='game_id')\n",
    "\n",
    "    full_df = pd.merge(temp_df, new_df, on=['game_id', 'nickname', 'bot_nickname'])\n",
    "\n",
    "    full_df[\"Player_Exchanged\"] = full_df[\"turn_type\"].apply(lambda x: 1 if \"Exchange\" in x else 0)\n",
    "    full_df[\"Player_Passed\"] = full_df[\"turn_type\"].apply(lambda x: 1 if \"Pass\" in x else 0)\n",
    "    full_df[\"Player_Six_Rule\"] = full_df[\"turn_type\"].apply(lambda x: 1 if \"Six-Zero Rule\" in x else 0)\n",
    "    full_df[\"Player_Challenged\"] = full_df[\"turn_type\"].apply(lambda x: 1 if \"Challenge\" in x else 0)\n",
    "\n",
    "\n",
    "    full_df[\"Bot_Exchanged\"] = full_df[\"bot_turn_type\"].apply(lambda x: 1 if \"Exchange\" in x else 0)\n",
    "    full_df[\"Bot_Passed\"] = full_df[\"bot_turn_type\"].apply(lambda x: 1 if \"Pass\" in x else 0)\n",
    "    full_df[\"Bot_Six_Rule\"] = full_df[\"bot_turn_type\"].apply(lambda x: 1 if \"Six-Zero Rule\" in x else 0)\n",
    "    full_df[\"Bot_Challenged\"] = full_df[\"bot_turn_type\"].apply(lambda x: 1 if \"Challenge\" in x else 0)\n",
    "\n",
    "    full_df.drop(columns=['turn_type', 'bot_turn_type'], inplace= True)\n",
    "\n",
    "    total_turns = turns_data.groupby(['game_id'])['turn_number'].max()\n",
    "    full_df = pd.merge(full_df, total_turns.reset_index(), on='game_id')\n",
    "\n",
    "    final_df = pd.merge(full_train, full_df, on=['game_id', 'nickname', 'bot_nickname'])\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Drop game_id and nickname\n",
    "\n",
    "def drop_columns(df):\n",
    "  df_new = df.drop(columns=['game_id', 'nickname'])\n",
    "  return df_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
